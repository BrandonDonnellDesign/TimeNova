import os
import time
import csv
from datetime import datetime
from playwright.sync_api import sync_playwright
import json
import re # Import regex for sanitizing folder names
from dotenv import load_dotenv

# --- Load environment variables from .env ---
load_dotenv()
NOVATIME_USERNAME = os.getenv("NOVATIME_USERNAME")
NOVATIME_PASSWORD = os.getenv("NOVATIME_PASSWORD")
LOGIN_URL = os.getenv("LOGIN_URL")
TIMESHEET_SELECTOR = os.getenv("TIMESHEET_SELECTOR")
API_PREFIX = os.getenv("API_PREFIX")

def sanitize_folder_name(name):
    """Sanitizes a string to be a valid folder name."""
    # Replace invalid characters with an underscore
    name = re.sub(r'[\\/:*?"<>|]', '_', name)
    # Replace spaces with underscores
    name = name.replace(' ', '_')
    return name

def login_and_grab_timesheet():
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        context = browser.new_context()
        page = context.new_page()
        page.set_viewport_size({"width": 2560, "height": 1440})

        # Use a fixed "temp" folder in the current working directory
        base_output_dir = os.path.join(os.getcwd(), "timeCard")
        os.makedirs(base_output_dir, exist_ok=True)
        print(f"üìÅ Base output directory: {base_output_dir}")
        now_str = datetime.now().strftime("%Y%m%d")

        # Prepare for data capture
        captured_json_data = {"data": None, "found": False}

        def handle_response(response):
            url = response.url
            if API_PREFIX in url:
                print(f"‚úÖ Found matching JSON API request: {url}")
                try:
                    # Capture the latest JSON data, don't process immediately
                    captured_json_data["data"] = response.body().decode("utf-8")
                    captured_json_data["found"] = True
                except Exception as e:
                    print(f"‚ùå Failed to capture JSON response body: {e}")

        page.on("response", handle_response)

        # 1) Go to login page
        page.goto(LOGIN_URL)
        page.wait_for_selector("#txtUserName")

        # 2) Login
        page.fill("#txtUserName", NOVATIME_USERNAME)
        page.fill("#txtPassword", NOVATIME_PASSWORD)
        page.click("input[value='Employee Web']")
        page.wait_for_load_state("networkidle")
        print("‚úÖ Logged in!")

        # 3) Go to Timesheet
        page.wait_for_selector("h4:has-text('Timesheet')")
        page.click("h4:has-text('Timesheet')")
        page.wait_for_load_state("networkidle")
        print(f"Page URL after Timesheet click: {page.url}")

        # 4) Find the iframe containing the timesheet
        max_wait_time = 120  # seconds
        start_time = time.time()
        timesheet_frame = None

        print("üîé Searching for timesheet iframe...")

        while time.time() - start_time < max_wait_time:
            for frame in page.frames:
                try:
                    # Check if "TimesheetSection" is in the frame's URL or content
                    if "TimesheetSection" in frame.url or "TimesheetSection" in frame.content():
                        print(f"‚úÖ Found timesheet in frame: {frame.url}")
                        timesheet_frame = frame
                        break
                except Exception as e:
                    pass # Silently ignore frames that can't be accessed
            if timesheet_frame:
                break
            time.sleep(1)

        if not timesheet_frame:
            print("‚ùå Could not find timesheet iframe after waiting.")
            browser.close()
            return

        # 5) Navigate directly to the iframe URL
        iframe_url = timesheet_frame.url
        print(f"üåê Navigating directly to timesheet iframe URL: {iframe_url}")
        page.goto(iframe_url)
        page.wait_for_load_state("networkidle")

        # Wait additional time for data and network requests
        print("‚è≥ Waiting 10 seconds for data and API request to finalize...")
        time.sleep(10) # Increased wait time to ensure all data is loaded and captured

        # --- Process and save JSON/CSV data only once here ---
        if captured_json_data["found"] and captured_json_data["data"]:
            try:
                json_data = captured_json_data["data"]

                # Parse JSON to extract WeekGroupString for folder naming
                timesheet_json = json.loads(json_data)
                records = timesheet_json.get("DataList", [])

                # --- Determine date range for folder name ---
                pay_period_start = pay_period_end = None
                for rec in records:
                    if rec.get("dPayPeriodStart") and rec.get("dPayPeriodEnd"):
                        pay_period_start = rec["dPayPeriodStart"]
                        pay_period_end = rec["dPayPeriodEnd"]
                        break
                if not (pay_period_start and pay_period_end):
                    work_dates = [rec.get("dWorkDate") for rec in records if rec.get("dWorkDate")]
                    if work_dates:
                        pay_period_start = min(work_dates)
                        pay_period_end = max(work_dates)
                # If no pay period or work dates found, skip processing
                if not pay_period_start or not pay_period_end:
                    print("No timecard data available yet")
                    return
                def fmt(dtstr):
                    if not dtstr:
                        return "unknown"
                    try:
                        dt = datetime.strptime(dtstr.split()[0], "%m/%d/%Y")
                        return dt.strftime("%m-%d-%y")
                    except Exception:
                        return "unknown"
                start_str = fmt(pay_period_start)
                end_str = fmt(pay_period_end)
                folder_name = f"{start_str}_to_{end_str}"
                folder_name = sanitize_folder_name(folder_name)
                # --- END date range for folder name ---

                # Create the new weekly output directory
                weekly_output_dir = os.path.join(base_output_dir, folder_name)
                os.makedirs(weekly_output_dir, exist_ok=True)
                print(f"üìÅ Output files will be saved in: {weekly_output_dir}")

                # Define file paths using the new weekly_output_dir
                json_filename = "timesheet.json"
                json_path = os.path.join(weekly_output_dir, json_filename)
                
                csv_filename = "timesheet.csv"
                csv_path = os.path.join(weekly_output_dir, csv_filename)

                screenshot_filename = "timesheet.png"
                screenshot_path = os.path.join(weekly_output_dir, screenshot_filename)

                # Save JSON
                with open(json_path, "w", encoding="utf-8") as f:
                    f.write(json_data)
                print(f"‚úÖ Timesheet JSON data saved at {json_path}")

                columns = [
                    "Date",
                    "Pay Code",
                    "In",
                    "Out",
                    "Reg",
                    "OT-1",
                    "OT-2",
                    "Daily Hours *",
                    "Shift Exp",
                    "Schedule",
                    "Total Hours\xa0*",
                    "Account",
                    "ActShortCode",
                    "Facility",
                ]

                column_field_map = {
                    "Date": "DateKey",
                    "Pay Code": "cPayCodeDescription",
                    "In": "dIn",
                    "Out": "dOut",
                    "Reg": "nWorkHours",
                    "OT-1": "nOT1Hours",
                    "OT-2": "nOT2Hours",
                    "Daily Hours *": "nDailyHours",
                    "Shift Exp": "cShiftExpression",
                    "Schedule": "cSchedule",
                    "Total Hours\xa0*": "nWeeklyHours",
                }

                # Save CSV
                with open(csv_path, "w", newline="", encoding="utf-8") as csvfile:
                    writer = csv.writer(csvfile)
                    writer.writerow(columns)
                    for rec in records:
                        row_data = []
                        account_value = ""
                        act_short_code_value = ""
                        facility_value = ""

                        for group in rec.get("GroupingList", []) + rec.get("GroupValueList", []):
                            if group.get("iGroupNumber") == 3:
                                account_value = group.get("cGroupValueDescription", "")
                                act_short_code_value = group.get("cGroupValue", "")
                            elif group.get("iGroupNumber") == 17:
                                facility_value = group.get("cGroupValueDescription", "")
                            elif group.get("iGroupNumber") == 16 and not facility_value:
                                facility_value = group.get("cGroupValueDescription", "")

                        for col in columns:
                            if col == "Account":
                                row_data.append(account_value)
                            elif col == "ActShortCode":
                                row_data.append(act_short_code_value)
                            elif col == "Facility":
                                row_data.append(facility_value)
                            else:
                                row_data.append(rec.get(column_field_map.get(col, col), ""))

                        writer.writerow(row_data)
                print(f"‚úÖ Timesheet CSV file saved at {csv_path}")

                # 6) Locate the timesheet table element (moved here as it depends on json processing success)
                timesheet_element = page.query_selector(TIMESHEET_SELECTOR)
                if not timesheet_element:
                    print("‚ùå Could not find timesheet element on iframe page for screenshot.")
                else:
                    # 7) Save screenshot
                    timesheet_element.screenshot(path=screenshot_path)
                    print(f"üì∏ Screenshot saved at {screenshot_path}")

                print("‚úÖ Script completed successfully with JSON and CSV saved.")

            except Exception as e:
                print(f"‚ùå Failed to process captured JSON data and save files: {e}")
        else:
            print("‚ùå Did not detect any JSON API requests matching the prefix. No files saved.")

        browser.close()

if __name__ == "__main__":
    if not NOVATIME_USERNAME or not NOVATIME_PASSWORD:
        print("‚ùå Missing NOVATIME_USERNAME or NOVATIME_PASSWORD in your .env file.")
    else:
        login_and_grab_timesheet()